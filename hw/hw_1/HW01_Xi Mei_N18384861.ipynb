{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Data Science\n",
    "## Homework 1: Due Midnight, March 4th. 1/3 of a Grade Deducted for each day late"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Student Name: Xi Mei\n",
    "\n",
    "Student Netid: xm518\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: Case study\n",
    "- Read [this article](http://www.nytimes.com/2012/02/19/magazine/shopping-habits.html) in the New York Times.\n",
    "- Use what we've learned in class and from the book to describe how one could set Target's problem up as a predictive modeling problem, such that they could have gotten the results that they did.  Formulate your solution as a proposed plan using our data science terminology.  Include all the aspects of the formulation that you see as relevant to solving the problem.  Be precise but concise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer_P1:\n",
    "** 1. Business understanding:<br />**\n",
    "The goal is prediction of female customers' pregnancy and delivery date;\n",
    "\n",
    "** 2. Data understanding:<br />**\n",
    "Considers each customer as an item of data with many attributes. Based on some relevant attribues, build a model to get the result of possiblity of pregnancy and date of delivery.\n",
    "\n",
    "**3. Data preparation:<br />**\n",
    "After their research, focus on the attributes data related to the 25 products they think is useful for their model.\n",
    "\n",
    "**4. Modeling:<br />**\n",
    "Analyze these relevant attributes data, give some weights to each product data, and  build a model, which can work out the result of possiblity of pregnancy and date of delivery of each female customer.\n",
    "\n",
    "**5. Evaluation:<br />**\n",
    "Check the fitness of this model by inviting some customers to do a questionnaire or just observing their behavior.\n",
    "\n",
    "**6. Deployment:<br />**\n",
    "Use verified model to predict female customers' pregnancy and delivery data and decide if the Target should send pregnancy products coupons or ads to them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: Dealing with messy data\n",
    "Not all data you will deal with is going to be clean. In fact, much of it will be very messy! For example, we have the HTML page that lists the contributors to Facebook's [osquery](https://github.com/facebook/osquery) project that is hosted on [Github.com](https://github.com). In this case, all we are interested in are the contributors and how many commits each of them has. Given the HTML page in `\"data/osquery_contributors.html\"` you will sift through tons of irrelevant data so that you can build a useful data structure.\n",
    "\n",
    "Notice that the first six (out of 59 total) contributors are named \"theopolis\", \"marpaia\", \"javuto\", \"jedi22\", \"unixist\", and \"mofarrell\". They have 553, 477, 104, 49, 30, 25 commits respectively.\n",
    "\n",
    "![Screenshot](images/osquery_contributors.png)\n",
    "\n",
    "To get a better of understanding of how this data is stored in the file, try searching through the raw data file for these usernames to look for any patterns. Your final dictionary should have 59 elements!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1\\. Turn this data into a Python dictionary called `contributors` where the keys are the contributor names and the values are the number of commits that each contributor has."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'theopolis': '553', 'marpaia': '477', 'javuto': '104', 'jedi22': '49', 'unixist': '30', 'mofarrell': '25', 'sharvilshah': '23', 'lwhsu': '22', 'wxsBSD': '20', 'polachok': '14', 'zwass': '14', 'eastebry': '9', 'maus-': '9', 'vmauge': '8', 'astanway': '6', 'maclennann': '6', 'blakefrantz': '6', 'akshaydixi': '5', 'arirubinstein': '4', 'cdown': '4', 'deniszh': '3', 'achmiel': '3', 'brandt': '3', 'nlsun': '3', 'mimeframe': '3', 'mgoffin': '2', 'mathieuk': '2', 'ga2arch': '2', 'glensc': '2', 'jreese': '2', 'Anubisss': '2', 'timzimmermann': '2', 'jamesgpearce': '2', 'schettino72': '2', 'castrapel': '2', 'mlw': '2', 'apage43': '1', 'SimplyAhmazing': '1', 'quad': '1', 'yannick': '1', 'blackfist': '1', 'DavidGosselin': '1', 'ecin': '1', 'arubdesu': '1', 'yetanotherhacker': '1', 'rjeczalik': '1', 'larzconwell': '1', 'justintime32': '1', 'alex': '1', 'vlajos': '1', 'dreid': '1', 'kost': '1', 'mtmcgrew': '1', 'tburgin': '1', 'mark-ignacio': '1', 'shawndavenport': '1', 'jacknagz': '1', 'd0ugal': '1', 'stevenhilder': '1'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "59"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "Part2Data = open(r\"C:\\Users\\Messimx\\Documents\\GitHub\\DataScienceCourse\\ipython\\hw\\hw_1\\data\\osquery_contributors.html\",\"r\", encoding=\"utf8\")\n",
    "Part2_str= Part2Data.read()\n",
    "pattern=re.compile(r'(author=)(.+)(\">)(\\d+)(\\scommit)')\n",
    "\n",
    "contributors = dict()\n",
    "for m in re.finditer(pattern,Part2_str):\n",
    "    contributors[m.group(2)]=m.group(4)\n",
    "    \n",
    "print(contributors)\n",
    "len(contributors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3: Dealing with data Pythonically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# You might find these packages useful. You may import any others you want!\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = np.array([0,1,1])\n",
    "if (np.any(np.less(x,np.zeros(x.shape)))):\n",
    "    print(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = np.array([0,1,1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1\\. Load the data set `\"data/ads_dataset.tsv\"` into a Python Pandas data frame called `ads`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ads' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-88e2d8e2117d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[1;31m# Place your code here\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mads\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr'C:\\Users\\Messimx\\Documents\\GitHub\\DataScienceCourse\\ipython\\hw\\hw_1\\data\\ads_dataset.tsv'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mheader\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnames\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mads\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mads\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ads' is not defined"
     ]
    }
   ],
   "source": [
    "# Place your code here\n",
    "ads=pd.read_csv(r'C:\\Users\\Messimx\\Documents\\GitHub\\DataScienceCourse\\ipython\\hw\\hw_1\\data\\ads_dataset.tsv',header=0,names=np.arange(ads.shape[1]))\n",
    "ads\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2\\. Write a Python function called `getDfSummary()` that does the following:\n",
    "- Takes as input a data frame\n",
    "- For each variable in the data frame calculates the following features:\n",
    "  - `number_nan` to count the number of missing not-a-number values\n",
    "  - Ignoring missing, NA, and Null values:\n",
    "    - `number_distinct` to count the number of distinct values a variable can take on\n",
    "    - `mean`, `max`, `min`, `std` (standard deviation), and `25%`, `50%`, `75%` to correspond to the appropriate percentiles\n",
    "- All of these new features should be loaded in a new data frame. Each row of the data frame should be a variable from the input data frame, and the columns should be the new summary features.\n",
    "- Returns this new data frame containing all of the summary information\n",
    "\n",
    "Hint: The pandas `describe()` [(manual page)](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.describe.html) method returns a useful series of values that can be used here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getDfSummary(input_data):\n",
    "    # Place your code here\n",
    "    DF=pd.DataFrame(input_data)\n",
    "    number_nan=DF.isnull().sum()\n",
    "    number_distinct=pd.Series()\n",
    "    for i in DF.columns:\n",
    "        number_distinct[i]=len(DF[i].unique())\n",
    "    output_data=DF.describe().transpose()\n",
    "    output_data['number_nan']=number_nan\n",
    "    output_data['number_distinct']=number_distinct\n",
    "    del output_data['count']\n",
    "    return output_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3\\. How long does it take for your `getDfSummary()` function to work on your `ads` data frame? Show us the results below.\n",
    "\n",
    "Hint: `%timeit getDfSummary(ads)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 loops, best of 3: 66.9 ms per loop\n"
     ]
    }
   ],
   "source": [
    "# Place your code here\n",
    "%timeit getDfSummary(ads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4\\. Using the results returned from `getDfSummary()`, which fields, if any, contain missing `NaN` values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "      <th>number_nan</th>\n",
       "      <th>number_distinct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>isbuyer</th>\n",
       "      <td>0.042632</td>\n",
       "      <td>0.202027</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>buy_freq</th>\n",
       "      <td>1.240653</td>\n",
       "      <td>0.782228</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>15.00000</td>\n",
       "      <td>52257</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>visit_freq</th>\n",
       "      <td>1.852777</td>\n",
       "      <td>2.921820</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>84.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>buy_interval</th>\n",
       "      <td>0.210008</td>\n",
       "      <td>3.922016</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>174.62500</td>\n",
       "      <td>0</td>\n",
       "      <td>295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sv_interval</th>\n",
       "      <td>5.825610</td>\n",
       "      <td>17.595442</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.104167</td>\n",
       "      <td>184.91670</td>\n",
       "      <td>0</td>\n",
       "      <td>5886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>expected_time_buy</th>\n",
       "      <td>-0.198040</td>\n",
       "      <td>4.997792</td>\n",
       "      <td>-181.9238</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>84.28571</td>\n",
       "      <td>0</td>\n",
       "      <td>348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>expected_time_visit</th>\n",
       "      <td>-10.210786</td>\n",
       "      <td>31.879722</td>\n",
       "      <td>-187.6156</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>91.40192</td>\n",
       "      <td>0</td>\n",
       "      <td>15135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last_buy</th>\n",
       "      <td>64.729335</td>\n",
       "      <td>53.476658</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>18.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>105.000000</td>\n",
       "      <td>188.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last_visit</th>\n",
       "      <td>64.729335</td>\n",
       "      <td>53.476658</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>18.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>105.000000</td>\n",
       "      <td>188.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>multiple_buy</th>\n",
       "      <td>0.006357</td>\n",
       "      <td>0.079479</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>multiple_visit</th>\n",
       "      <td>0.277444</td>\n",
       "      <td>0.447742</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uniq_urls</th>\n",
       "      <td>86.569343</td>\n",
       "      <td>61.969765</td>\n",
       "      <td>-1.0000</td>\n",
       "      <td>30.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>155.000000</td>\n",
       "      <td>206.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_checkins</th>\n",
       "      <td>720.657592</td>\n",
       "      <td>1275.727306</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>127.0</td>\n",
       "      <td>319.0</td>\n",
       "      <td>802.000000</td>\n",
       "      <td>37091.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>4628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y_buy</th>\n",
       "      <td>0.004635</td>\n",
       "      <td>0.067924</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           mean          std       min    25%    50%  \\\n",
       "isbuyer                0.042632     0.202027    0.0000    0.0    0.0   \n",
       "buy_freq               1.240653     0.782228    1.0000    1.0    1.0   \n",
       "visit_freq             1.852777     2.921820    0.0000    1.0    1.0   \n",
       "buy_interval           0.210008     3.922016    0.0000    0.0    0.0   \n",
       "sv_interval            5.825610    17.595442    0.0000    0.0    0.0   \n",
       "expected_time_buy     -0.198040     4.997792 -181.9238    0.0    0.0   \n",
       "expected_time_visit  -10.210786    31.879722 -187.6156    0.0    0.0   \n",
       "last_buy              64.729335    53.476658    0.0000   18.0   51.0   \n",
       "last_visit            64.729335    53.476658    0.0000   18.0   51.0   \n",
       "multiple_buy           0.006357     0.079479    0.0000    0.0    0.0   \n",
       "multiple_visit         0.277444     0.447742    0.0000    0.0    0.0   \n",
       "uniq_urls             86.569343    61.969765   -1.0000   30.0   75.0   \n",
       "num_checkins         720.657592  1275.727306    1.0000  127.0  319.0   \n",
       "y_buy                  0.004635     0.067924    0.0000    0.0    0.0   \n",
       "\n",
       "                            75%          max  number_nan  number_distinct  \n",
       "isbuyer                0.000000      1.00000           0                2  \n",
       "buy_freq               1.000000     15.00000       52257               11  \n",
       "visit_freq             2.000000     84.00000           0               64  \n",
       "buy_interval           0.000000    174.62500           0              295  \n",
       "sv_interval            0.104167    184.91670           0             5886  \n",
       "expected_time_buy      0.000000     84.28571           0              348  \n",
       "expected_time_visit    0.000000     91.40192           0            15135  \n",
       "last_buy             105.000000    188.00000           0              189  \n",
       "last_visit           105.000000    188.00000           0              189  \n",
       "multiple_buy           0.000000      1.00000           0                2  \n",
       "multiple_visit         1.000000      1.00000           0                2  \n",
       "uniq_urls            155.000000    206.00000           0              207  \n",
       "num_checkins         802.000000  37091.00000           0             4628  \n",
       "y_buy                  0.000000      1.00000           0                2  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Place your code here\n",
    "getDfSummary(ads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer_Q4:\n",
    "Since only \"buy_freq\" field has non-0 result in \"number_nan\" column, \"buy_freq\" field contains missing NaN values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5\\. For the fields with missing values, does it look like the data is missing at random? Are there any other fields that correlate perfectly, or predict that the data is missing? If missing, what should the data value be?\n",
    "\n",
    "Hint: create another data frame that has just the records with a missing value. Get a summary of this data frame using `getDfSummary()` and compare the differences. Do some feature distributions change dramatically?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "      <th>number_nan</th>\n",
       "      <th>number_distinct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>isbuyer</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>buy_freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>52257</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>visit_freq</th>\n",
       "      <td>1.651549</td>\n",
       "      <td>2.147955</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>84.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>buy_interval</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sv_interval</th>\n",
       "      <td>5.686388</td>\n",
       "      <td>17.623555</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>184.91670</td>\n",
       "      <td>0</td>\n",
       "      <td>5112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>expected_time_buy</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>expected_time_visit</th>\n",
       "      <td>-9.669298</td>\n",
       "      <td>31.239030</td>\n",
       "      <td>-187.6156</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>91.40192</td>\n",
       "      <td>0</td>\n",
       "      <td>13351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last_buy</th>\n",
       "      <td>65.741317</td>\n",
       "      <td>53.484622</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>19.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>106.000000</td>\n",
       "      <td>188.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last_visit</th>\n",
       "      <td>65.741317</td>\n",
       "      <td>53.484622</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>19.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>106.000000</td>\n",
       "      <td>188.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>multiple_buy</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>multiple_visit</th>\n",
       "      <td>0.255602</td>\n",
       "      <td>0.436203</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uniq_urls</th>\n",
       "      <td>86.656180</td>\n",
       "      <td>61.996711</td>\n",
       "      <td>-1.0000</td>\n",
       "      <td>30.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>155.000000</td>\n",
       "      <td>206.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_checkins</th>\n",
       "      <td>721.848518</td>\n",
       "      <td>1284.504018</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>126.0</td>\n",
       "      <td>318.0</td>\n",
       "      <td>803.000000</td>\n",
       "      <td>37091.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>4570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y_buy</th>\n",
       "      <td>0.003024</td>\n",
       "      <td>0.054904</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           mean          std       min    25%    50%  \\\n",
       "isbuyer                0.000000     0.000000    0.0000    0.0    0.0   \n",
       "buy_freq                    NaN          NaN       NaN    NaN    NaN   \n",
       "visit_freq             1.651549     2.147955    1.0000    1.0    1.0   \n",
       "buy_interval           0.000000     0.000000    0.0000    0.0    0.0   \n",
       "sv_interval            5.686388    17.623555    0.0000    0.0    0.0   \n",
       "expected_time_buy      0.000000     0.000000    0.0000    0.0    0.0   \n",
       "expected_time_visit   -9.669298    31.239030 -187.6156    0.0    0.0   \n",
       "last_buy              65.741317    53.484622    0.0000   19.0   52.0   \n",
       "last_visit            65.741317    53.484622    0.0000   19.0   52.0   \n",
       "multiple_buy           0.000000     0.000000    0.0000    0.0    0.0   \n",
       "multiple_visit         0.255602     0.436203    0.0000    0.0    0.0   \n",
       "uniq_urls             86.656180    61.996711   -1.0000   30.0   75.0   \n",
       "num_checkins         721.848518  1284.504018    1.0000  126.0  318.0   \n",
       "y_buy                  0.003024     0.054904    0.0000    0.0    0.0   \n",
       "\n",
       "                            75%          max  number_nan  number_distinct  \n",
       "isbuyer                0.000000      0.00000           0                1  \n",
       "buy_freq                    NaN          NaN       52257                1  \n",
       "visit_freq             2.000000     84.00000           0               48  \n",
       "buy_interval           0.000000      0.00000           0                1  \n",
       "sv_interval            0.041667    184.91670           0             5112  \n",
       "expected_time_buy      0.000000      0.00000           0                1  \n",
       "expected_time_visit    0.000000     91.40192           0            13351  \n",
       "last_buy             106.000000    188.00000           0              189  \n",
       "last_visit           106.000000    188.00000           0              189  \n",
       "multiple_buy           0.000000      0.00000           0                1  \n",
       "multiple_visit         1.000000      1.00000           0                2  \n",
       "uniq_urls            155.000000    206.00000           0              207  \n",
       "num_checkins         803.000000  37091.00000           0             4570  \n",
       "y_buy                  0.000000      1.00000           0                2  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ads_nan=ads.loc[(np.isnan(ads.buy_freq))]\n",
    "getDfSummary(ads_nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "#To check if when \"isbuy\"=0, \"buy_freq\"=NaN and when \"isbuy\"=1, \"buy_freq\" is a numerica data\n",
    "check=1\n",
    "for row in range(0,len(ads.index)):\n",
    "    if np.isnan(ads.iat[row,1]):\n",
    "        if ads.iat[row,0]!=0:\n",
    "            check=0\n",
    "    else:\n",
    "        if ads.iat[row,0]!=1:\n",
    "            check=0\n",
    "print(check)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer_Q5:\n",
    "After we delete the rows with numeric data in \"buy_freq\" column, we can see some differences in the result of getDfSummary(): <br />\n",
    "For \"isbuyer\", \"buy_interval\", \"expected_time_buy\", \"multiple_buy\", they change result from 2 to 1. When we review the original file of \"ads\", we find only \"isbuy\" field kind of correlates with \"buy_freq\". So we verify our guess by above coding. The result tell us: when \"isbuy\"=0, \"buy_freq\"=NaN and when \"isbuy\"=1, \"buy_freq\" is a numerica data, which is the pattern \"buy_freq\" follows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6\\. Which variables are binary?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['isbuyer', 'multiple_buy', 'multiple_visit', 'y_buy']\n"
     ]
    }
   ],
   "source": [
    "# Place your code here\n",
    "DF_new=getDfSummary(ads)\n",
    "binarylist=list()\n",
    "for i in DF_new.index:\n",
    "    if DF_new.at[i,'number_distinct']==2:\n",
    "        binarylist.append(i)\n",
    "print(binarylist)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
